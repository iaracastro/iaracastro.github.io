---
tags: statistics
title: EMV
#published: false
sidebar:
    nav: docs-en
---

## EMV ou MLE: $\theta_{E M V}$

O estimador de máxima verossimilhança (EMV) de uma amostra é aquele que maximiza a função de verossimilhança $L(\theta)=f_n(\bar{x} \mid \theta)$.

$$\hat{\theta}=\text{argmax} L_x(\theta)$$

Ps:. Maximizar $L(\theta)$ é o mesmo que maximizar $\log L(\theta)$ : "deriva e iguala a $0 "$.

$$(\log L(\theta))^{\prime}=0$$

Ps:. Maximizar $L(\theta)$ também é o mesmo que minimizar $-L(\theta)$.

### Exemplos

#### Uniforme:

$$\begin{aligned}
& \hat{\theta_2}=\max \{x_1, x_2, \ldots, x_n\} \\
& \hat{\theta_1}=\min \{x_1, x_2, \ldots, x_n\}
\end{aligned}$$

Quando $\theta_1=0$ : intervalo $[0, \theta]$

$$\theta=\max (X_1, X_2, \ldots, X_n)$$

##### Prova:

$$L(\theta)=f_n\left(\bar{x} \mid \theta_1, \theta_2\right)=\frac{1}{\left(\theta_2-\theta_1\right)^n}$$

$L(\theta)$ é maximizado quando $\left(\theta_2 - \theta_1\right)$ é mínimo.

$$\begin{aligned}
& \hat{\theta_1} = \max \{ x_1, x_2, \ldots, x_n \} \\
& \hat{\theta_2} = \min \{ x_1, x_2, \ldots, x_n \}
\end{aligned}$$

Quando $\theta_1=0$ :

$$L(\theta)=f_n(\bar{x} \mid \theta)=\frac{1}{(\theta)^n) \mathbb{I} \{ x_1, x_2, \ldots, x_n\} \ \leq \theta}$$

$L(\theta)$ é maximizado quando $\theta$ é máximo.

#### Binomial:

$$\hat{\theta}=\overline{x_n}$$

##### Prova:
$$\begin{gathered}
L(\theta)=f_n(\bar{x} \mid \theta)=\prod_{i=1}^n\left(\begin{array}{c}
n \\
x_i
\end{array}\right) \theta^y(1-\theta)^{n-y}, y=\sum_1^n x_i \\
\log L(\theta)=\sum_{i=1}^n \log \left(\left(\begin{array}{c}
n \\
x_i
\end{array}\right)\right)+y \log (\theta)+(n-\theta) \log (1-\theta) \\
(\log L(\theta))^{\prime}=0 \leftrightarrow=\frac{y}{\theta}-(n-y) \frac{1}{1-\theta}=0 \\
y(1-\theta)=\theta(n-y) \leftrightarrow y - \not{\theta y} =\theta n - \not{\theta y} \\
y=\theta n \leftrightarrow \theta=\frac{y}{n}=\frac{\sum_1^n x_i}{n}=\overline{x_n}
\end{gathered}$$

#### Exponencial:

$$\hat{\theta}=\frac{1}{\overline{x_n}}$$

##### Prova:

$$\begin{gathered}
L(\theta)=f_n(\bar{x} \mid \theta)=\theta^n e^{-\theta y}, y=\sum_1^n x_i \\
\log L(\theta)=n \log (\theta)-\theta y=n \log (\theta)-\theta \sum_1^n x_i \\
(\log L(\theta))^{\prime}=0 \leftrightarrow \frac{n}{\theta}-\sum_1^n x_i=0 \\
\frac{n}{\theta}=\sum_1^n x_i \leftrightarrow \theta=\frac{n}{\sum_1^n x_i}=\frac{1}{\overline{x_n}}
\end{gathered}$$

#### Bernoulli:

$$\hat{\theta}=\overline{x_n}$$

##### Prova:

$$\begin{gathered}
L(\theta)=f_n(\bar{x} \mid \theta)=\theta^y(1-\theta)^{n-y}, y=\sum_1^n x_i \\
\log L(\theta)=y \log (\theta)+(n-y)(\log (1-\theta)) \\
(\log L(\theta))^{\prime}=0 \leftrightarrow \frac{y}{\theta}-\frac{n-y}{(1-\theta)}=0 \\
\frac{y}{\theta}=\frac{n-y}{1-\theta} \leftrightarrow y(1-\theta)=\theta(n-y) \\
y-\not y y=n \theta-\not y \\
\theta=\frac{y}{n}=\frac{\sum_1^n x_i}{n}=\overline{x_n}
\end{gathered}$$

#### Poisson:

$$\hat{\theta}=\overline{x_n}$$

##### Prova:

$$\begin{gathered}
L(\theta)=f_n(\bar{x} \mid \theta)=\frac{e^{-n \theta} \theta^y}{\prod x_{i} !}, y=\sum_1^n x_i \\
\log (L(\theta))=y \log (\theta)-n \theta-\log \left(\prod x_{i} !\right) \\
(\log L(\theta))^{\prime}=0 \leftrightarrow \frac{y}{\theta}-n=0 \\
\frac{y}{\theta}=n \leftrightarrow \frac{\sum_1^n x_i}{n}=n \leftrightarrow \theta=\overline{x_n}
\end{gathered}$$

#### Normal:

- $\hat{\theta}=\{\hat{\mu}, \hat{\sigma^2}\}$ :

$$\hat{\mu} = \bar{X}_n$$

$$\hat{\sigma^2 } = \frac{1}{n} \sum_{i=1}^n\left(X_i-\mu\right)^2$$
